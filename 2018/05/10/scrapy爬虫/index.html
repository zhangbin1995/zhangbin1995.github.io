<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.2" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.2">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.2" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.4.2',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="技术选型 scrapy vs requests + beautifulsoup   1.requests和beautifulsoup都是库，scrapy是框架 2.scrapy框架中可以加入requests和beautifulsoup 3.scrapy基于twisted，性能是最大的优势 4.scrapy方便扩展，提供了很多内置的功能 5.scrapy内置的css和xpath selector非常">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="scrapy爬虫">
<meta property="og:url" content="http://www.herobin.top/2018/05/10/scrapy爬虫/index.html">
<meta property="og:site_name" content="HeroBin&#39;s Blog">
<meta property="og:description" content="技术选型 scrapy vs requests + beautifulsoup   1.requests和beautifulsoup都是库，scrapy是框架 2.scrapy框架中可以加入requests和beautifulsoup 3.scrapy基于twisted，性能是最大的优势 4.scrapy方便扩展，提供了很多内置的功能 5.scrapy内置的css和xpath selector非常">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-01-14T03:10:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="scrapy爬虫">
<meta name="twitter:description" content="技术选型 scrapy vs requests + beautifulsoup   1.requests和beautifulsoup都是库，scrapy是框架 2.scrapy框架中可以加入requests和beautifulsoup 3.scrapy基于twisted，性能是最大的优势 4.scrapy方便扩展，提供了很多内置的功能 5.scrapy内置的css和xpath selector非常">



  <link rel="alternate" href="/atom.xml" title="HeroBin's Blog" type="application/atom+xml" />




  <link rel="canonical" href="http://www.herobin.top/2018/05/10/scrapy爬虫/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>scrapy爬虫 | HeroBin's Blog</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f6e0affa56b837b3134c1b097c760963";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/zhangbin1995"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">HeroBin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">向阳而生</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.herobin.top/2018/05/10/scrapy爬虫/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="HeroBin">
      <meta itemprop="description" content="记录学习生活的点点滴滴">
      <meta itemprop="image" content="/uploads/we.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HeroBin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">scrapy爬虫
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-05-10 10:21:17" itemprop="dateCreated datePublished" datetime="2018-05-10T10:21:17+08:00">2018-05-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-01-14 11:10:08" itemprop="dateModified" datetime="2019-01-14T11:10:08+08:00">2019-01-14</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <span class="post-meta-divider">|</span>
            <span id="busuanzi_value_page_pv"></span>次阅读
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong>技术选型</strong></p>
<p>scrapy vs requests + beautifulsoup</p>
<blockquote>
<ul>
<li>1.requests和beautifulsoup都是库，scrapy是框架</li>
<li>2.scrapy框架中可以加入requests和beautifulsoup</li>
<li>3.scrapy基于twisted，性能是最大的优势</li>
<li>4.scrapy方便扩展，提供了很多内置的功能</li>
<li>5.scrapy内置的css和xpath selector非常方便，beautifulsoup最大的缺点就是慢</li>
</ul>
</blockquote>
<p><strong>网页分类</strong></p>
<blockquote>
<ul>
<li>1.静态网页</li>
<li>2.动态网页</li>
<li>3.webservice(restapi)</li>
</ul>
</blockquote>
<p><strong>爬虫作用</strong></p>
<blockquote>
<ul>
<li>1.搜索引擎—百度、google、垂直领域搜索引擎</li>
<li>2.推荐引擎—今日头条</li>
<li>3.机器学习的数据样本</li>
<li>4.数据分析（如金融数据分析）、舆情分析等</li>
</ul>
</blockquote>
<p><strong>正则表达式</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">^[0-9]+abc$</span><br><span class="line">^为匹配输入字符串的开始位置</span><br><span class="line">[0-9]+匹配多个数字，[0-9]匹配单个数字，+匹配一个或者多个</span><br><span class="line">abc$匹配字母abc并以abc结尾，$为匹配输入字符串的结束位置</span><br></pre></td></tr></table></figure>
<p>实例</p>
<p>匹配以数字开头，并以abc结尾的字符串：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">var str = &quot;123abc&quot;;</span><br><span class="line">var str1 = &quot;12323123abc&quot;;</span><br><span class="line">var str2 = &quot;12323123abcabc&quot;;</span><br><span class="line">var patt1 = /^[0-9]+abc$/;</span><br><span class="line">document.write(str.match(patt1));</span><br><span class="line">输出结果</span><br><span class="line">123abc</span><br><span class="line">12323123abc</span><br><span class="line">null</span><br></pre></td></tr></table></figure>
<p><strong>为什么使用正则表达式</strong></p>
<p>典型的搜索和替换操作要求提供与预期的搜索结果匹配的确切文本。虽然这种技术对于对静态文本执行简单搜索和替换任务可能已经足够了，但它缺乏灵活性，若采用这种方法搜索动态文本，即使不是不可能，至少也会变得很困难。</p>
<p>通过使用正则表达式，可以：</p>
<blockquote>
<ul>
<li>测试字符串的模式。<br>例如，可以测试输入字符串，以查看字符串是否出现电话号码模式或者信用卡号码模式。这称为数据验证。<br>*替换文本<br>可以使用正则表达式来识别文档中的特定文本，完全删除该文本或者用其他文本替换它。</li>
<li>基于模式匹配从字符串中提取子字符串</li>
<li>可以查找文档内或输入域内特定的文本   </li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">line = &quot;bobby123&quot;</span><br><span class="line">reges_str = &quot;^b.*&quot;</span><br><span class="line">if re.match(reges_str,line):</span><br><span class="line">    print(&quot;yes&quot;)</span><br><span class="line">else:</span><br><span class="line">    print(&quot;no&quot;)</span><br><span class="line"></span><br><span class="line"># ^b.* :以b开头的后面任意字符任意多个     .任意字符    *任意多个</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">line = &quot;booooooobby123&quot;</span><br><span class="line">regex_str = &quot;.*(b.*b).*&quot;</span><br><span class="line">match_obj = re.match(regex_str,line)</span><br><span class="line">if match_obj:</span><br><span class="line">    print(match_obj.group(1))</span><br></pre></td></tr></table></figure>
<p>输出结果：bb<br>因为是贪婪匹配 从后往前匹配的   booooooobby123</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">line = &quot;booooooobby123&quot;</span><br><span class="line">regex_str = &quot;.*?(b.*b).*&quot;</span><br><span class="line">match_obj = re.match(regex_str,line)</span><br><span class="line">if match_obj:</span><br><span class="line">    print(match_obj.group(1))</span><br></pre></td></tr></table></figure>
<p>输出结果：booooooob</p>
<p>贪婪匹配：在满足匹配时，匹配尽可能长的字符串，默认情况下，采用贪婪匹配</p>
<p>非贪婪匹配：在满足匹配时，匹配尽可能短的字符串，使用?来表示非贪婪匹配</p>
<p>特殊字符</p>
<blockquote>
<ul>
<li>1) ^ $ * ? + {2} {2,} {2,5} |</li>
<li>2) []：字符集合         [^]：负值字符集合，匹配未包含的         [a-z]      </li>
<li>3) \s \S \w \W     空格    a-zA-Z0-9_</li>
<li>4) <code>[\u4E00-\u9FA5] () \d</code>     中文    数字</li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># _*_ coding: utf-8 _*_</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">##提取生日的小demo</span><br><span class="line">line = &quot;XXX出生于2001年6月1日&quot;</span><br><span class="line">#line = &quot;XXX出生于2001/6/1&quot;</span><br><span class="line">#line = &quot;XXX出生于2001-6-1&quot;</span><br><span class="line">#line = &quot;XXX出生于2001-06-01&quot;</span><br><span class="line">#line = &quot;XXX出生于2001-06&quot;</span><br><span class="line">regex_str = &quot;.*出生于(\d&#123;4&#125;[年/-]\d&#123;1,2&#125;([月/-]\d&#123;1,2&#125;|[月/-]$|$))&quot;</span><br><span class="line">match_obj = re.match(regex_str,line)</span><br><span class="line">if match_obj:</span><br><span class="line">    print(match_obj.group(1))</span><br></pre></td></tr></table></figure>
<p><strong>深度优先和广度优先</strong></p>
<p>深度优先过程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def depth_tree(tree_node):</span><br><span class="line">    if tree_node is not None:</span><br><span class="line">        print(tree_node._data)</span><br><span class="line">        if tree_node._left is not None:</span><br><span class="line">            return depth_tree(tree_node._left)</span><br><span class="line">        if tree_node._right is not None:</span><br><span class="line">            return depth_tree(tree_node._right)</span><br></pre></td></tr></table></figure>
<p>广度优先过程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def level_queue(root):</span><br><span class="line">    &quot;&quot;&quot;利用队列实现树的广度优先遍历&quot;&quot;&quot;</span><br><span class="line">    if root is None:</span><br><span class="line">        return</span><br><span class="line">    my_queue = []</span><br><span class="line">    node = root</span><br><span class="line">    my_queue.append(node)</span><br><span class="line">    while my_queue:</span><br><span class="line">        node = my_queue.pop(0)</span><br><span class="line">        print(node.elem)</span><br><span class="line">        if node.lchild is not None:</span><br><span class="line">            my_queue.append(node.lchild)</span><br><span class="line">        if node.rchild is not None:</span><br><span class="line">            my_queue.append(node.rchild)</span><br></pre></td></tr></table></figure></p>
<p>爬虫去重策略</p>
<blockquote>
<ul>
<li>1.将访问过的url保存到数据库中</li>
<li>2.将访问过的url保存到set中，只需要o(1)的代价就可以查询url<br>因为存在内存中，所以对内存要求较高，例如一亿个url占用空间<br><code>100000000*2byte*50</code>个字符/1024/1024/1024=9G</li>
<li>3.url经过md5等方法哈希后保存到set中 （scrapy用的就是这个）</li>
<li>4.用bitmap方法，将访问过的url通过hash函数映射到某一位</li>
<li>5.bloomfilter方法对bitmap进行改进，多重hash函数降低冲突</li>
</ul>
</blockquote>
<p>字符串编码</p>
<blockquote>
<ul>
<li>1.计算机只能处理数字，文本转换为数字才能处理。计算机中8个bit作为一个字节，所以一个字节能表示最大的数字就是255</li>
<li>2.计算机是美国人发明的，所以一个字节可以表示所有字符了，所以ASCII（一个字节）编码就成为美国人的标准编码</li>
<li>3.但是ASCII处理中文明显是不够的，中文不止255个汉字，所以中国制定了GB2312编码，用两个字节表示一个汉字。GB2312还把ASCII包含进去了，同理，日文，韩文等等上百个国家为了解决这个问题就都发展了一套字节的编码，标准就越来越多，如果出现多种语言混合显示就一定会出现乱码</li>
<li>4.于是unicode出现了，将所有语言统一到一套编码里</li>
<li><ol start="5">
<li>看一下ASCII和unicode编码：<br>1）字母A用ASCII编码十进制是65，二进制0100 0001<br>2）汉字“中”已近超出了ASCII编码的范围，用unicode编码是20013 二进制是01001110 00101101<br>3）A用unicode编码只需要前面补0二进制是00000000 0100 0001</li>
</ol>
</li>
<li>6.乱码问题解决了，但是如果内容全是英文，unicode编码比ASCII需要多一倍的存储空间，同时如果传输需要多一倍的传输。</li>
<li>7.所以出现了可变长的编程“utf-8”，把英文边长一个字节，汉字3个字节。特别生僻的变成4-6字节，如果传输大量的英文，utf8作用就很明显了</li>
</ul>
</blockquote>
<p>安装virtualenv步骤<br><a href="https://www.cnblogs.com/anpengapple/p/6430022.html" target="_blank" rel="noopener">https://www.cnblogs.com/anpengapple/p/6430022.html</a></p>
<p>指定python版本的virtualenv环境</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv -p python3 virtualtest1</span><br></pre></td></tr></table></figure>
<p>scrapy爬取伯乐在线</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv article_spider</span><br><span class="line">pip install -i https://pypi.douban.com/simple/ scrapy</span><br><span class="line"></span><br><span class="line">workon  查看所有虚拟环境</span><br><span class="line">workon article_spider   选取（切换）目标环境</span><br><span class="line">scrapy startproject ArticleSpider  新建scrapy项目</span><br><span class="line">然后去pcharm里打开这个项目  ArticleSpider</span><br><span class="line">cd ArticleSpider</span><br><span class="line">scrapy genspider jobbole blog.jobbole.com</span><br></pre></td></tr></table></figure>
<p>启动爬虫时 要将settings.py中的 ROBOTSTXT_OBEY = False 注释放开</p>
<p><strong>xpath</strong><br>1.xpath简介</p>
<blockquote>
<ul>
<li>①xpath使用路径表达式在xml和html中进行导航</li>
<li>②xpath包含标准函数库</li>
<li>③xpath是一个w3c的标准</li>
</ul>
</blockquote>
<p>xpath节点关系</p>
<blockquote>
<ul>
<li>父节点 子节点 同胞节点 先辈节点 后代节点</li>
</ul>
</blockquote>
<p>2.xpath术语</p>
<p>3.xpath语法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">article	选取所有article元素的所有子节点</span><br><span class="line">/articel	选取根节点article</span><br><span class="line">article/a	选取所有属于article的子元素的a元素</span><br><span class="line">//div	选取所有div子元素（不论出现在文档任何地方）</span><br><span class="line">article//div选取所有属于article元素的后代的div元素，不管他出现在article之下的任何位置</span><br><span class="line">//@class	选取所有名为class的属性</span><br><span class="line"></span><br><span class="line">/article/div[1]		选取属于article子元素的第一个div元素</span><br><span class="line">/article/div[last()]	选取属于article子元素的最后一个div元素</span><br><span class="line">/article/div[last()-1]	选取属于article子元素的倒数第二个div元素</span><br><span class="line">//div[@lang]		选取所有拥有lang属性的div元素</span><br><span class="line">//div[@lang=&apos;eng&apos;]	选取所有lang属性为eng的div元素</span><br><span class="line"></span><br><span class="line">/div/*			选取属于div元素的所有子节点</span><br><span class="line">//*				选取所有元素</span><br><span class="line">//div[@*]			选取所有带属性的title元素</span><br><span class="line">/div/a | //div/p	选取所有div元素的a和p元素</span><br><span class="line">//span | //ul		选取文档中的span和ul元素</span><br><span class="line">article/div/p | //span选取所有属于article元素的div元素的p元素 以及文档中所有的span元素</span><br><span class="line"></span><br><span class="line">scrapy shell http://blog.jobbole.com/110287</span><br><span class="line">命令行对一个url进行调试  进入命令行模式后</span><br><span class="line">title = response.xpath(&quot;//div[@class=&apos;entry-header&apos;]/h1/text()&quot;)</span><br><span class="line">title</span><br><span class="line">#输出 [&lt;Selector xpath=&quot;//div[@class=&apos;entry-header&apos;]/h1/text()&quot; data=&apos;2016 腾讯软件开发面试题（部分）&apos;&gt;]</span><br><span class="line">title.extract()</span><br><span class="line">[&apos;2016 腾讯软件开发面试题（部分）&apos;]</span><br><span class="line">title.extract()[0]</span><br><span class="line">&apos;2016 腾讯软件开发面试题（部分）&apos;</span><br><span class="line"></span><br><span class="line">将日期里面的 . 和空格去掉</span><br><span class="line">date = response.xpath(xxxxxxxx.extract()[0].strip().replace(&quot; . &quot;,&quot; &quot;).strip())</span><br></pre></td></tr></table></figure>
<p>css选择器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">*			选择所有节点</span><br><span class="line">#container	选择id为container的节点</span><br><span class="line">.container	选取所有class包含container的节点</span><br><span class="line">li a			选取所有li下的所有a节点</span><br><span class="line">ul+p		选取ul后面的第一个p元素</span><br><span class="line">div#container&gt;ul	选取id为container的div的第一个ul子元素 </span><br><span class="line">ul ~ p		选取与ul相邻的所有p元素</span><br><span class="line">a[title]		 选取所有有title属性的a元素</span><br><span class="line">a[href=&quot;http://jobbole.com&quot;]	选取所有href属性为jobbole.com值得元素</span><br><span class="line">a[href*=&quot;jobbole&quot;]	选取所有href属性包含jobbole的a元素</span><br><span class="line">a[href^=&quot;http&quot;]	选取所有href属性值以http开头的a元素</span><br><span class="line">a[href$=&quot;.jpg&quot;]	选取所有href属性值以.jpg结尾的a元素</span><br><span class="line">input[type=radio]:checked	选择选中的radio的元素</span><br><span class="line">div:not(#container)	选取所有id非container的div属性</span><br><span class="line">li:nth-child(3)		选取第三个li元素</span><br><span class="line">tr:nth-child(2n)	第偶数个tr</span><br><span class="line"></span><br><span class="line">提取文本 ::text</span><br><span class="line">response.css(&quot;.entry-header h1::text&quot;).extract()</span><br><span class="line"></span><br><span class="line">scrapy shell blog.jobbole.com/all-posts/</span><br><span class="line">response.css(&quot;#archive .floated-thumb .post-thumb a::attr(href)&quot;).extract()</span><br><span class="line">Out[1]: </span><br><span class="line">[&apos;http://blog.jobbole.com/113771/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113768/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/112048/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113760/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113740/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113631/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113737/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113735/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113707/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113728/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113722/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113726/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113719/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113716/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113710/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113713/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113705/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113699/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113696/&apos;,</span><br><span class="line"> &apos;http://blog.jobbole.com/113692/&apos;]</span><br><span class="line"></span><br><span class="line">next_urls = response.css(&quot;.next.page-numbers&quot;)</span><br><span class="line">next_urls = response.css(&quot;.next .page-numbers&quot;)</span><br><span class="line">两个class next和page-numbers中如果没有空格说明是一个模块里的两个class属性 同级的</span><br><span class="line">如果有空格 说明是下级关系 </span><br><span class="line">&lt;div class=&quot;next page-numbers&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class=&quot;next&quot;&gt;</span><br><span class="line">&lt;div class=&quot;page-numbers&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">1. 获取文章列表页中的文章url并交给scrapy下载后并进行解析</span><br><span class="line">2. 获取下一页的url并交给scrapy进行下载， 下载完成后交给parse</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">#解析列表页中的所有文章url并交给scrapy下载后并进行解析</span><br><span class="line">if response.status == 404:</span><br><span class="line">    self.fail_urls.append(response.url)</span><br><span class="line">    self.crawler.stats.inc_value(&quot;failed_url&quot;)</span><br><span class="line"></span><br><span class="line">post_nodes = response.css(&quot;#archive .floated-thumb .post-thumb a&quot;)</span><br><span class="line">for post_node in post_nodes:</span><br><span class="line">    image_url = post_node.css(&quot;img::attr(src)&quot;).extract_first(&quot;&quot;)</span><br><span class="line">    post_url = post_node.css(&quot;::attr(href)&quot;).extract_first(&quot;&quot;)</span><br><span class="line">    yield Request(url=parse.urljoin(response.url, post_url), meta=&#123;&quot;front_image_url&quot;:image_url&#125;, callback=self.parse_detail)</span><br><span class="line"></span><br><span class="line">#提取下一页并交给scrapy进行下载</span><br><span class="line">next_url = response.css(&quot;.next.page-numbers::attr(href)&quot;).extract_first(&quot;&quot;)</span><br><span class="line">if next_url:</span><br><span class="line">    yield Request(url=parse.urljoin(response.url, next_url), callback=self.parse)</span><br></pre></td></tr></table></figure>
<p><strong>scrapy的item类</strong></p>
<p>item只有Filed一个类型</p>
<p>使用item与pipeline保存数据</p>
<blockquote>
<ul>
<li>在item中定义需要保存的内容，然后在pipeline处理item，爬虫流程就成了这样：<br>抓取 –&gt; 按item规则收集需要数据 –&gt; 使用pipeline处理（存储等）</li>
</ul>
</blockquote>
<p>如果我们获取了图片的地址想保存图片怎么办？<br>scrapy提供了图片自动下载机制</p>
<p>文件的打开和关闭：codecs<br>import codecs</p>
<p><code>self.file = codes.open(&#39;article.json&#39;, &#39;w&#39;, encoding=&quot;utf-8&quot;) #w代表以写的方式打开</code></p>
<p>scrapy.exporters可以协助pipeline将item导出为各种格式<br>例如导出json<br>from scrapy.exporters import JsonItemExporter</p>
<p>与mysql的整合</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line">import MySQLdb</span><br><span class="line">class MysqlPipeline(object):</span><br><span class="line">#采用同步的机制写入mysql</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.conn = MySQLdb.connect(&apos;host&apos;, &apos;user&apos;, &apos;password&apos;, &apos;dbname&apos;, charset=&quot;utf8&quot;, use_unicode=True)</span><br><span class="line">        self.cursor = self.conn.cursor() #执行数据库</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        insert_sql = &quot;&quot;&quot;</span><br><span class="line">            insert into jobbole_article(title, url, create_date, fav_nums)</span><br><span class="line">            VALUES (%s, %s, %s, %s)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.cursor.execute(insert_sql, (item[&quot;title&quot;], item[&quot;url&quot;], item[&quot;create_date&quot;], item[&quot;fav_nums&quot;]))</span><br><span class="line">  self.conn.commit()</span><br><span class="line">execute执行时会执行完再向下进行，造成阻塞</span><br><span class="line">可以种连接池来使数据库操作变成异步操作</span><br><span class="line"></span><br><span class="line">可以将mysql的配置信息写在setting中</span><br><span class="line">MYSQL_HOST = &quot;127.0.0.1&quot;</span><br><span class="line">MYSQL_DBNAME = &quot;article&quot;</span><br><span class="line">MYSQL_USER = &quot;root&quot;</span><br><span class="line">MYSQL_PASSWORD = &quot;1234&quot;</span><br><span class="line">然后在pipelines中通过@classmethod引入</span><br><span class="line">通过from twisted.enterprise import adbapi来调用twisted来异步</span><br><span class="line"></span><br><span class="line">from twisted.enterprise import adbapi</span><br><span class="line"> </span><br><span class="line">import codecs</span><br><span class="line">import MySQLdb</span><br><span class="line">import MySQLdb.cursors</span><br><span class="line">class MysqlTwistedPipeline(object):</span><br><span class="line">    def __init__(self, dbpool):</span><br><span class="line">        self.dbpool = dbpool</span><br><span class="line">    @classmethod</span><br><span class="line">    def from_settings(cls, settings):</span><br><span class="line">        dbparms = dict(</span><br><span class="line">            host = settings[&quot;MYSQL_HOST&quot;],</span><br><span class="line">            db = settings[&quot;MYSQL_DBNAME&quot;],</span><br><span class="line">            user = settings[&quot;MYSQL_USER&quot;],</span><br><span class="line">            passwd = settings[&quot;MYSQL_PASSWORD&quot;],</span><br><span class="line">            charset = &quot;utf8&quot;,</span><br><span class="line">            cursorclass = MySQLdb.cursors.DictCursor,</span><br><span class="line">            use_unicode = True,</span><br><span class="line">        )</span><br><span class="line">        dbpool = adbapi.ConnectionPool(&quot;MySQLdb&quot;, **dbparms)</span><br><span class="line">        return cls(dbpool)</span><br><span class="line">    def process_item(self, item, spidre):</span><br><span class="line">        #使用twisted将mysql插入变成异步执行</span><br><span class="line">        query = self.dbpool.runInteraction(self.do_insert, item)</span><br><span class="line">        query.addErrback(self.handle_error)#处理异常</span><br><span class="line">    def handle_error(self, failure):4</span><br><span class="line">        #处理异步插入的异常</span><br><span class="line">        print (failure)</span><br><span class="line">    def do_insert(self, cursor, item):</span><br><span class="line">        #执行具体的插入</span><br><span class="line">        insert_sql = &quot;&quot;&quot;</span><br><span class="line">                    insert into jobbole_article(title, url, url_object_id, create_date, fav_nums)</span><br><span class="line">                    VALUES (%s, %s, %s, %s, %s)</span><br><span class="line">                &quot;&quot;&quot;</span><br><span class="line">        cursor.execute(insert_sql,(item[&quot;title&quot;], item[&quot;url&quot;], item[&quot;url_object_id&quot;], item[&quot;create_date&quot;], item[&quot;fav_nums&quot;]))</span><br><span class="line"></span><br><span class="line">使用ItemLoader爬取数据</span><br><span class="line">from scrapy.loader import ItemLoader</span><br><span class="line">#通过item loader加载item</span><br><span class="line">item_loader = ItemLoader(item=JobbolenArticleItem(), response=response)</span><br><span class="line">item_loader.add_css(&quot;title&quot;, &quot;.entry-header h1::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;create_date&quot;, &quot;p.entry-meta-hide-on-mobile::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;praise_nums&quot;, &quot;.vote-post-up h10::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;comment_nums&quot;, &quot;a[href=&apos;#article-comment&apos;] span::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;fav_nums&quot;, &quot;.bookmark-btn::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;tags&quot;, &quot;p.entry-meta-hide-on-mobile a::text&quot;)</span><br><span class="line">item_loader.add_css(&quot;content&quot;, &quot;div.entry&quot;)</span><br><span class="line">item_loader.add_value(&quot;url&quot;, response.url)</span><br><span class="line">item_loader.add_value(&quot;url_object_id&quot;, get_md5(response.url))</span><br><span class="line">item_loader.add_value(&quot;front_image_url&quot;, [front_image_url])</span><br><span class="line"></span><br><span class="line">article_item = item_loader.load_item()</span><br><span class="line"></span><br><span class="line">可以通过在 item中编写处理函数</span><br><span class="line">import scrapy</span><br><span class="line">import datetime</span><br><span class="line">import re</span><br><span class="line">from scrapy.loader.processors import MapCompose, TakeFirst, Join</span><br><span class="line">from scrapy.loader import ItemLoader</span><br><span class="line"></span><br><span class="line">class ArticlespiderItem(scrapy.Item):</span><br><span class="line">    # define the fields for your item here like:</span><br><span class="line">    # name = scrapy.Field()</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def add_jobbole(value):</span><br><span class="line">    return value+&quot;-bobby&quot;</span><br><span class="line"></span><br><span class="line">def date_convert(value):</span><br><span class="line">    try:</span><br><span class="line">        create_date = datetime.datetime.strptime(value, &quot;%Y/%m/%d&quot;).date()</span><br><span class="line">    except Exception as e:</span><br><span class="line">        create_date = datetime.datetime.now().date()</span><br><span class="line">    return create_date</span><br><span class="line"></span><br><span class="line">def get_nums(value):</span><br><span class="line">    match_re = re.match(&quot;.*?(\d+).*&quot;, value)</span><br><span class="line">    if match_re:</span><br><span class="line">        nums = int(match_re.group(1))</span><br><span class="line">    else:</span><br><span class="line">        nums = 0</span><br><span class="line">    return nums</span><br><span class="line"></span><br><span class="line">def remove_commit_tags(value):</span><br><span class="line">    #去掉tag中提取的评论</span><br><span class="line">    if &quot;评论&quot; in value:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line">    else:</span><br><span class="line">        return value</span><br><span class="line"></span><br><span class="line">def return_value(value):</span><br><span class="line">    return value</span><br><span class="line"></span><br><span class="line">class ArticleItemLoader(ItemLoader):</span><br><span class="line">    #自定义itemLoader</span><br><span class="line">    default_output_processor = TakeFirst()</span><br><span class="line"></span><br><span class="line">class JobbolenArticleItem(scrapy.Item):</span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    create_date = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(date_convert),</span><br><span class="line">        #output_processor = TakeFirst() #只取第一个</span><br><span class="line">    )</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    url_object_id = scrapy.Field()</span><br><span class="line">    front_image_url = scrapy.Field(</span><br><span class="line">        output_processor = MapCompose(return_value)</span><br><span class="line">    )</span><br><span class="line">    front_image_path = scrapy.Field()</span><br><span class="line">    praise_nums = scrapy.Field(</span><br><span class="line">        input_processor = MapCompose(get_nums),</span><br><span class="line">    )</span><br><span class="line">    comment_nums = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(get_nums),</span><br><span class="line">    )</span><br><span class="line">    fav_nums = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(get_nums)</span><br><span class="line">    )</span><br><span class="line">    tags = scrapy.Field(</span><br><span class="line">        input_processor=MapCompose(remove_commit_tags),</span><br><span class="line">        output_processor=Join(&quot;,&quot;)</span><br><span class="line">    )</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/09/pip国内镜像源/" rel="next" title="pip国内镜像源">
                <i class="fa fa-chevron-left"></i> pip国内镜像源
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/12/scrapy爬虫于反爬虫/" rel="prev" title="scrapy爬虫于反爬虫">
                scrapy爬虫于反爬虫 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/we.jpg"
                alt="HeroBin" />
            
              <p class="site-author-name" itemprop="name">HeroBin</p>
              <p class="site-description motion-element" itemprop="description">记录学习生活的点点滴滴</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">58</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">HeroBin</span>

  

  
</div>



<!-- 
  
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动 v3.7.1</div>



  <span class="post-meta-divider">|</span>
 -->

<!-- 
  <div class="theme-info">主题 – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Mist</a> v6.4.2</div>
 -->

<div>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv" style='display:none'>
    本站总访问量 <span id="busuanzi_value_site_pv"></span> 次
    <span class="post-meta-divider">|</span>
</span>
<span id="busuanzi_container_site_uv" style='display:none'>
    有<span id="busuanzi_value_site_uv"></span>人看过我的博客啦
</span>
</div>





  <div class="theme-info">主题 – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Mist</a> v6.4.2</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共84.2k字</span>
</div>
 


        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.4.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.2"></script>



  



  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  

  

  

  

  

  
<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>

</body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
